= Digital Modernization

:imagesdir: ../../images
:icons: font

== EKS Continuous Integration/Continuous Delivery (CI/CD)

****
*Expected Outcome:*

* 300 level understaing of Kubernetes Continuous Deployment:
** Create a source code repository using AWS CodeCommit.
** Configure a CI/CD pipeline using AWS CodePipeline.
** Deploy AWS CodeBuild to build your container image and push to ECS.

*Lab Requirements*

* Cloud9 IDE.
* an Amazon Elastic Container Service for Kubernetes Cluster.

*Average Lab Time:*
45-60 minutes
****

=== Introduction
This module is designed to improve your undesrtanding of the link:https://aws.amazon.com/codestar/[AWS Code*] services like, link:https://aws.amazon.com/codecommit/[AWS CodeCommit], link:https://aws.amazon.com/codebuild/[AWS CodeBuild], link:https://aws.amazon.com/codepipeline/[AWS Codepipeline] and link:https://aws.amazon.com/lambda/[AWS Lambda] can be used for continuous deployment on link:https://aws.amazon.com/eks/[Amazon EKS].

The following *Reference Architecture* details the how the above AWS services will be leveraged and the specific steps we will follow for this module.

=== Reference Architecure
image:architecture.png[Architecture]

=== Setting up the CI/CD Pipeline

NOTE: The following section of the module assumes a working EKS cluster, created in *Amazon EKS* module.

To start, we need to assign a *ServiceRole* to CodePipeline, as permissions for some aspects of the pipeline execution process are granted to another role type that acts on behalf of CodePipeline, like EKS, rather than to IAM users.

The Service role is an IAM role that gives CodePipeline permission to use resources in your account. Service role creation is only required the first time you create a pipeline in CodePipeline.

CodePipeline uses this service role when processing revisions through the stages and actions in a pipeline. That role is configured with one or more policies that control access to the AWS resources used by the pipeline. You might want to attach additional policies to this role, edit the policy attached to the role, or configure policies for other service roles in AWS. You might also want to attach a policy to a role when configuring cross-account access to your pipeline. 

Step 1:: In the Cloud9 IDE `terminal`, navigate to this modules working directory.
+
[source,shell]
----
cd ~/environment/aws-modernization-workshop/modules/cicd/
----
+
Step 2:: Next we wil create the necessary Service Roles using the CloudFormation template in this modules wotking directory by running the follopwing AWS CLI command:
+
[source,shell]
----
aws cloudformation create-stack --stack-name "eks-cicd-demo-roles" \
--template-body=file://eks-cicd-roles-template.yaml \
--capabilities CAPABILITY_IAM
----
+
Example Output:
+
[.output]
----
{
    "StackId": "arn:aws:cloudformation:us-west-2:<REDACTED>:stack/workshop-cicd-roles/686a6510-79b7-11e9-a777-0a58a0e3e17a"
}
----

==== Create Container Repository

Step 1:: As we saw with the other examples in this workshop, we will need to store our demo applications' docker containers, so next we'll create an AWS ECR respository for the application contianers by running the following command:
+ 
[source,shell]
----
aws ecr create-repository --repository-name eks-cicd-demo-repo --region us-west-2
----
+
Example Output:
+
[.output]
----
{
    "repository": {
        "registryId": "<REDACTED>", 
        "repositoryName": "eks-cicd-demo-repo", 
        "repositoryArn": "arn:aws:ecr:us-west-2:<.REDACTED>:repository/eks-cicd-demo-repo", 
        "createdAt": 1558127545.0, 
        "repositoryUri": "<REDACTED>.dkr.ecr.us-west-2.amazonaws.com/eks-cicd-demo-repo"
    }
}
----

==== Create Source Version Control for the Demo Applicaiton

Step 1:: Next we will create an AWS CodeCommit repository to store the source code for our sample EKS project. This is the source code for the application we are "developing" and will eventually push to "production" using our CI/CD Pipeline. Execute the following command in the Ckoud9 `terminal`.
+
[source,shell]
----
aws codecommit create-repository --repository-name eks-cicd-demo-repo --repository-description "EKS CICD demo application repository" --region us-west-2
----
+
Example Output:
+
[.output]
----
{
    "repositoryMetadata": {
        "repositoryName": "eks-cicd-demo-repo", 
        "cloneUrlSsh": "ssh://git-codecommit.us-west-2.amazonaws.com/v1/repos/eks-cicd-demo-repo", 
        "lastModifiedDate": 1558126857.734, 
        "repositoryDescription": "EKS CICD demonstration repository", 
        "cloneUrlHttp": "https://git-codecommit.us-west-2.amazonaws.com/v1/repos/eks-cicd-demo-repo", 
        "creationDate": 1558126857.734, 
        "repositoryId": "1d5e262b-ff0a-4555-a552-31a87db6373a", 
        "Arn": "arn:aws:codecommit:us-west-2:<REDACTED>:eks-cicd-demo-repo", 
        "accountId": "<REDACTED>"
    }
}
----
+
Step 2:: Next we will commit out sample application to the CodeCommit reposutory created above, by running the following commands:
+
[source,shell]
----
git config --global credential.helper '!aws codecommit credential-helper $@'

git config --global credential.UseHttpPath true

git clone https://git-codecommit.us-west-2.amazonaws.com/v1/repos/eks-cicd-demo-repo

cp ./sample-app/* eks-cicd-demo-repo/

cd eks-cicd-demo-repo

git add . && git commit -m "initial commit of sample app" && git push origin master
----

==== Create the Pipeline

Step 1:: Now that we have a place to store our docker container, a source code repository and the necessary Service roles, we can create our CI/CD Pipeline. Open a broweser tab and navigate to the link:https://us-west-2.console.aws.amazon.com/codesuite/codepipeline/pipelines[AWS CodePipeline] Service Console. Click on *Create pipeline*.
+
image:create-pipeline.png[Create Pipeline]
+
Step 2:: After the *Create new pipline* wizard opens, the first step is to configure the *Pipeline settings*. Enter `EKS-CICD-Demo` as the *Pipeline name*. Select *Existing service role* and from the drop-down, select the IAM role we created in *Step 2*.
+
NOTE: The *Role name* should start with `eks-cicd-demo-roles-CodepipleServiceRole-...`.
+
Step 3:: Under *Artifact store*, click *Custom location*. From the *Bucket* drop-down list, select the S3 Buvket created in *Step 2*.
+
NOTE: The *Bucket* name should start with `eks-cicd-demo-roles-ekscicddemobucket-...`.
+
Step 4:: Click on *Next* to continue.
+
image:pipeline-settings.png[Pipeline Settings]
+
Step 5:: Next we'll configure the *Source stage*. Click the drop-down and select *AWS CodeComkit* as the *Source provider*.
+
Step 6:: For the *Repository name*, click the drop-down to select the repository we created in *Step 4*, `eks-cicd-demo-repo`.
+
Step 7:: Select the `master` branch from the drop-down for *Brnach name*.
+
Step 8:: Kepp the default recommended setting for *Change detection options* as *Amazon CloudWatch* and click *Next*.
+
image:pipeline-source.png[Pipeline Source]
+
Step 9:: Now we configure the *Build stage*. Click the drop-down and select *AWS CodeBuild* and then click the *Create project* link to create a new CodeBuild project.
+
image:create-project.png[Create Build]
+
Step 10:: A new browser window will open to create a new build project. Under the *Project configuration* section, enter `eks-build-project` as the *Project name* and provide an option *Description*.
+
image:build-project.png[Project Name]
+
TIP: Even though it's not required for this workshop, it's always a good practice to tag your AWS resources for _Cost Allocation_, _Access Control_, _Business Organization_ and _Automation_. You can read more about Tagging Strategies link:https://aws.amazon.com/answers/account-management/aws-tagging-strategies/[here].
+
Step 11:: Under the *Environment* section, ensure that *Managed image* is selected.
+
Step 12:: From the *Operating system* drop-down box, select *Ubuntu*.
+
Step 13:: Leave the *Runtime* as *Standard* and ensure that the you select `aws/codebuild/standard:2.0` as the *Image*.
+
Step 14:: For the *Service role*, select *Existing service role* and choose the role we created in *Step 2*.
+
NOTE: The *Role name* should start with `eks-cicd-demo-roles-CodeBuildServiceRole-...`.
+
Step 15:: Uncheck the *Allow AWS CodeBuild to modify this service role* check-box.
+
image:build-environment.png[Build Environment]
+
Step 16:: Expand the *Additional configuration* section and add the following *Environmental variables* as the `Name`:
+
* `AWS_ACCOUNT_ID` - Add your 12 digit AWS Account as the value.
* `IMAGE_REPO_NAME` - Add `eks-cicd-demo-repo` as the value.
+
IMPORTANT: Make sure there are no spaces in any of the values entered!
+
image:build-variables.png[Environmental Variables]
+
Step 17:: Leave the rest of the fields as their default and click *Continue to CodePipeline*. You will be returned to the CodePipeline build stage. Click *Next* to continue.
+
image:build-complete.png[Build Complete]
+
Step 18:: Click *Skip deploy stage* and confirm.
+
NOTE: We will not create a *Deployment Stage* to our pipeline because we will leverage an link:https://aws.amazon.com/lambda/[AWS Lambda] to handle the deployment to Kubernetes.
+
image:skip-deployment.png[Skip Deploy Stage]
+
Setp 19:: Review the CodePipeline configuration and click *Create Pipeline*.
+
image:pipeline-success.png[Build Complete]

==== Deploying the Application to EKS
Now that we have created and tested the build of our pipeline in CodePipeline, we will next create an AWS Lambda function to as as a Kubernetes client and deploy the application to EKS.

Step 1:: Let's get started setting up the lambda function by first ensuring we are the paret of the modules' working directory. In the Cloud9 IDE `terminal`, run the following command:
+
[source,shell]
----

----

[red yellow-background big]*TO BE CONTINUED*

Step 6:: Lambda client for Kubernetes
+
[source,shell]
----
cd ..
git clone https://github.com/BranLiang/lambda-eks
cd lambda-eks

sed -i -e "s#\$EKS_CA#$(aws eks describe-cluster --name k8s-workshop --query cluster.certificateAuthority.data --output text)#g" ./config
sed -i -e "s#\$EKS_CLUSTER_HOST#$(aws eks describe-cluster --name k8s-workshop --query cluster.endpoint --output text)#g" ./config
sed -i -e "s#\$EKS_CLUSTER_NAME#k8s-workshop#g" ./config
sed -i -e "s#\$EKS_CLUSTER_USER_NAME#lambda#g" ./config
----
+
Step 7:: Check secrets
+
[source,shell]
----
kubectl get secrets
----
+
Expected Output:
+
[.output]
----
NAME                  TYPE                                  DATA      AGE
default-token-dwfwk   kubernetes.io/service-account-token   3         22m
----
+
Step 8:: Update Token
+
[source,shell]
----
sed -i -e "s#\$TOKEN#$(kubectl get secret $SECRET_NAME -o json | jq -r '.data["token"]' | base64 -d)#g" ./config
----
+
Step 9:: Build, Package, deploy
+
[source,shell]
----
npm install
zip -r lambda-package_v1.zip .
export LAMBDA_SERVICE_ROLE=$(aws cloudformation describe-stacks --stack-name $AWS_MASTER_STACK | jq -r '.Stacks[0].Outputs[]|select(.OutputKey=="LambdaExecutionRoleArn")|.OutputValue')
aws lambda create-function --function-name LambdaKubeClient --runtime nodejs8.10 --role $LAMBDA_SERVICE_ROLE --handler index.handler  --zip-file fileb://lambda-package_v1.zip --timeout 10 --memory-size 128
----
+
Step 10:: Prioviuding admin access
+
[source,shell]
----
kubectl create clusterrolebinding default-admin --clusterrole cluster-admin --serviceaccount=default:default
----
+
Step 11:: Add deployment stage
+
BLAH B:AH B:AH
+
Step 12:: Test
